{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMzj6C7LeQGM"
      },
      "outputs": [],
      "source": [
        "from packaging import version\n",
        "\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Hr7nCph3kHXn",
        "outputId": "bc2b4b4f-00ef-4e9c-8f0e-f80717efdc31"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "This script exctracts training variables from all logs from\n",
        "tensorflow event files (\"event*\"), writes them to Pandas\n",
        "and finally stores in long-format to a CSV-file including\n",
        "all (readable) runs of the logging directory.\n",
        "The magic \"5\" infers there are only the following v.tags:\n",
        "[lr, loss, acc, val_loss, val_acc]\n",
        "'''\n",
        "\n",
        "import tensorflow as tf\n",
        "import glob\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get all event* runs from logging_dir subdirectories\n",
        "logging_dir = './all_logs/'\n",
        "event_paths = glob.glob(os.path.join(logging_dir,\"event*\"))\n",
        "\n",
        "\n",
        "# Extraction function\n",
        "def sum_log(path):\n",
        "    #runlog = pd.DataFrame(columns=['metric', 'value'])\n",
        "    logs = pd.DataFrame(columns=[\"step\", \"step_s\", \"D/loss_real\",\"D/loss_fake\",\"D/loss_cls\",\"D/loss_gp\",\"D/loss_total\",\"G/loss_fake\",\"G/loss_rec\",\"G/loss_cls\",\"G/loss_total\"])\n",
        "    content = {\"step\" : 0 , \"step_s\" : 0 , \"D/loss_real\":0.0,\"D/loss_fake\":0.0,\"D/loss_cls\":0.0,\"D/loss_gp\":0.0,\"D/loss_total\":0.0,\"G/loss_fake\":0.0,\"G/loss_rec\":0.0,\"G/loss_cls\":0.0,\"G/loss_total\":0.0}\n",
        "    c = 0\n",
        "\n",
        "    for e in tf.compat.v1.train.summary_iterator(path):\n",
        "        c += 1\n",
        "        content[\"step_s\"] = int(e.step)\n",
        "        content[\"step\"] = int(e.step)\n",
        "        for v in e.summary.value:\n",
        "            content[v.tag] = np.fromstring(v.tensor.tensor_content,dtype=np.float32).item()\n",
        "        if(c%9 == 0):\n",
        "\n",
        "            logs = pd.concat([logs, pd.DataFrame([content.copy()])], ignore_index=True)\n",
        "\n",
        "\n",
        "    # Dirty catch of DataLossError\n",
        "\n",
        "    return logs\n",
        "\n",
        "# Call & append\n",
        "all_log = pd.DataFrame()\n",
        "for path in event_paths:\n",
        "    log = sum_log(path)\n",
        "    if log is not None:\n",
        "        if all_log.shape[0] == 0:\n",
        "            all_log = log\n",
        "        else:\n",
        "            all_log = pd.concat([all_log,log], ignore_index = True)\n",
        "\n",
        "\n",
        "\n",
        "all = all_log.copy()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "all_log = all.copy()\n",
        "all_log = all_log.sort_values(by=['step_s'])\n",
        "all_log = all_log.drop_duplicates(\"step\")\n",
        "\n",
        "for i in pd.DataFrame(all_log).columns:\n",
        "    if(i == \"step\" or i == \"step_s\"):\n",
        "        continue\n",
        "    e = all_log.plot(x = 'step', y = i, subplots=True, figsize=(15,5), fontsize=17)[0].get_figure()\n",
        "    e.savefig(\"Loss_visualization/\" + i.split('/')[0] + \"_\" + i.split('/')[1] + \".jpg\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "log_2d = pd.DataFrame()\n",
        "log_2d = sum_log(\"2d_log/events.out.tfevents.1713409479.e57bfb76452f.4583.0.v2\")\n",
        "\n",
        "all_log = all.copy()\n",
        "log2 = log_2d.copy()\n",
        "\n",
        "all_log = all_log.sort_values(by=['step_s'])\n",
        "all_log = all_log.drop_duplicates(\"step\")\n",
        "all_log = all_log[all_log[\"step\"] <= 10000]\n",
        "log2 = log2.sort_values(by=['step_s'])\n",
        "log2 = log2.drop_duplicates(\"step\")\n",
        "\n",
        "print(len(all_log))\n",
        "print(len(log2))\n",
        "\n",
        "for i in pd.DataFrame(all_log).columns:\n",
        "    if(i == \"step\" or i == \"step_s\"):\n",
        "        continue\n",
        "    f = log2.plot.line(x = 'step', y = i, subplots=True, figsize=(15,5), fontsize=17, color=\"red\")\n",
        "    e = all_log.plot.line(x = 'step', y = i, subplots=True, figsize=(15,5), fontsize=17, ax = f)\n",
        "    f = f[0].get_figure()\n",
        "    f.savefig(\"compare_loss/\" + i.split('/')[0] + \"_\" + i.split('/')[1] + \"_compare.jpg\")\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
